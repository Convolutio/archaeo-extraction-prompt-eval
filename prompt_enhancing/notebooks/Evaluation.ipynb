{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Pipeline try\n",
    "\n",
    "We have selected some PDF samples with already-encoded text to test a complete pipeline worflow until the structured data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## MLFLow experiment setup\n",
    "\n",
    "Be sure to have run the mlflow server with this command at in the `prompt_enhancing/` directory\n",
    "\n",
    "```sh\n",
    "just serve-tracer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from archaeo_super_prompt.env import getenv_or_throw\n",
    "\n",
    "EXP_NAME = \"NAIVE CHUNK SELECTION\"\n",
    "mlflow.set_tracking_uri(f\"http://{getenv_or_throw(\"MLFLOW_HOST\")}:{getenv_or_throw(\"MLFLOW_PORT\")}\")\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "mlflow.dspy.autolog()\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Sample selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from archaeo_super_prompt.dataset.load import MagohDataset\n",
    "from archaeo_super_prompt.types.pdfpaths import buildPdfPathDataset\n",
    "\n",
    "ds = MagohDataset(200, 0.8, True)\n",
    "selected_ids = {\n",
    "31049, 30913\n",
    "}\n",
    "\n",
    "selected_files = [\n",
    "    (31049, Path(\".cache/pdfs/31049/Relazione_storica_Pasquinucci.pdf\").resolve()),\n",
    "    (30913, Path(\".cache/pdfs/30913/Relazione_assistenza.pdf\").resolve()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Pipeline run\n",
    "\n",
    "We use a dataframe-suitable version of the scikit-learn pipelines to pipe each module in this order :\n",
    "\n",
    "- ocr\n",
    "- layout text reading + chunking\n",
    "- strucured data extraction\n",
    "\n",
    "The LLM calls are traced by the MLFlow intergration and are viewable within links displayed by the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.pipeline import Pipeline\n",
    "from typing import cast\n",
    "from archaeo_super_prompt.pdf_to_text import OCR_Transformer, TextExtractor\n",
    "from archaeo_super_prompt.main_transformer import MagohDataExtractor\n",
    "\n",
    "import mlflow\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"ocr\", OCR_Transformer),\n",
    "        (\"pdf_reader\", TextExtractor),\n",
    "        (\"extractor\", MagohDataExtractor()),\n",
    "    ]\n",
    "\n",
    ")\n",
    "inputs = buildPdfPathDataset(selected_files)\n",
    "with mlflow.start_run():\n",
    "    score_value = pipeline.score(inputs, ds)\n",
    "score_results = cast(MagohDataExtractor,\n",
    "                     pipeline.named_steps[\"extractor\"]).score_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Evaluation result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html, callback, Output, Input, dash_table, dcc\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Dash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "field_grouping_keys = [\"field_name\", \"evaluation_method\"]\n",
    "\n",
    "resultsPerField = {fieldName: {\"method\": evalMethod, \"table\": resultForField.drop(columns=field_grouping_keys)}\n",
    "                   for (fieldName, evalMethod), resultForField in\n",
    "                   score_results.groupby(field_grouping_keys)}\n",
    "fieldNames = list(resultsPerField.keys())\n",
    "\n",
    "app.layout = [\n",
    "    html.H1(children='Results', style={'textAlign': 'center'}),\n",
    "    html.H2(children='Global results'),\n",
    "    dcc.Graph(figure=px.histogram(\n",
    "        score_results, y='field_name', x='metric_value', histfunc='avg')\n",
    "             ),\n",
    "    html.H2(children='Per field results'),\n",
    "    dcc.Dropdown(fieldNames, 'university__Sigla', id='dropdown-selection'),\n",
    "    html.H3(children=\"Evaluation method used\"),\n",
    "    html.Blockquote(id='eval-method-description'),\n",
    "    dash_table.DataTable(id='table-content', page_size=10)\n",
    "]\n",
    "\n",
    "@callback(\n",
    "    Output('eval-method-description', 'children'),\n",
    "    Input('dropdown-selection', 'value')\n",
    ")\n",
    "def updateEvalMethod(fieldName: str):\n",
    "    return f\"Evaluation method used: {resultsPerField[fieldName][\"method\"]}\"\n",
    "\n",
    "\n",
    "@callback(\n",
    "    Output('table-content', 'data'),\n",
    "    Input('dropdown-selection', 'value')\n",
    ")\n",
    "def updatePerFieldResultTable(fieldName: str):\n",
    "    return resultsPerField[fieldName][\"table\"].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
