{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Pipeline try\n",
    "\n",
    "We have selected some PDF samples with already-encoded text to test a complete pipeline worflow until the structured data extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## MLFLow experiment setup\n",
    "\n",
    "Be sure to have run the mlflow server with this command at in the `prompt_enhancing/` directory\n",
    "\n",
    "```sh\n",
    "just serve-tracer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from archaeo_super_prompt.env import getenv_or_throw\n",
    "\n",
    "EXP_NAME = \"NAIVE CHUNK SELECTION\"\n",
    "mlflow.set_tracking_uri(f\"http://{getenv_or_throw(\"MLFLOW_HOST\")}:{getenv_or_throw(\"MLFLOW_PORT\")}\")\n",
    "mlflow.set_experiment(EXP_NAME)\n",
    "mlflow.dspy.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Sample selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from archaeo_super_prompt.dataset.load import MagohDataset\n",
    "from archaeo_super_prompt.types.pdfpaths import buildPdfPathDataset\n",
    "\n",
    "ds = MagohDataset(200, 0.8, True)\n",
    "selected_ids = {\n",
    "31049, 30913\n",
    "}\n",
    "\n",
    "selected_files = [\n",
    "    (31049, Path(\".cache/pdfs/31049/Relazione_storica_Pasquinucci.pdf\").resolve()),\n",
    "    (30913, Path(\".cache/pdfs/30913/Relazione_assistenza.pdf\").resolve()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Pipeline run\n",
    "\n",
    "We use a dataframe-suitable version of the scikit-learn pipelines to pipe each module in this order :\n",
    "\n",
    "- ocr\n",
    "- layout text reading + chunking\n",
    "- strucured data extraction\n",
    "\n",
    "The LLM calls are traced by the MLFlow intergration and are viewable within links displayed by the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.pipeline import Pipeline\n",
    "from archaeo_super_prompt.pdf_to_text import OCR_Transformer, TextExtractor\n",
    "from archaeo_super_prompt.main_transformer import MagohDataExtractor\n",
    "\n",
    "import mlflow\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"ocr\", OCR_Transformer),\n",
    "        (\"pdf_reader\", TextExtractor),\n",
    "        (\"extractor\", MagohDataExtractor()),\n",
    "    ]\n",
    "\n",
    ")\n",
    "inputs = buildPdfPathDataset(selected_files)\n",
    "with mlflow.start_run():\n",
    "    results = pipeline.score(inputs, ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Evaluation result inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, predictions, _ = zip(*results[1])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
