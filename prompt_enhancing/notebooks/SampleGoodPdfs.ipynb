{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.pipeline import Pipeline\n",
    "from archaeo_super_prompt.dataset.load import MagohDataset\n",
    "from archaeo_super_prompt.pdf_to_text import OCR_Transformer, TextExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "With exploring the layout and the profile of the downloaded reports, we select some intervention identifiers that can be processable for a study of the chunks and the LLM interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = MagohDataset(200, 0.3, True)\n",
    "_selected_ids = [\n",
    "    # very good\n",
    "    33799, 34439, 38005, 36837, 36937, 37614, 37026, 37971, 36846, 36304, 34423, 36052,\n",
    "    37043, 36055, 36554, 989, 37007, 30897, 36351, 36308, 38013, 36011, 33828, 1221,\n",
    "    38039, 35429, 37065, 37116, 34452, 33441, 33062, 34939, 35918, 33689, 34508, 31035,\n",
    "    38220, 38092, 36979, 36854, 36207, 34915, 33439, 35688, 36359,\n",
    "    # not that good\n",
    "    31164, 32600, 33760, 32714, 31208, 30712, \n",
    "    ]\n",
    "selected_ids = set(_selected_ids)\n",
    "inputs = ds.get_files_for_batch(selected_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"ocr\", OCR_Transformer()),\n",
    "    (\"pdf_reader\", TextExtractor())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = pipeline.transform(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedChunks = { id_: { filename: fileChunks for filename, fileChunks in inpt.groupby(\"filename\") } for id_, inpt in texts.groupby(\"id\") }\n",
    "groupedChunks[31049][\"Relazione_storica_Pasquinucci.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = texts[(texts[\"id\"] == 31049) & (texts[\"filename\"] == \"Relazione_storica_Pasquinucci.pdf\")]\n",
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Chunk information\n",
    "\n",
    "From each chunk, we can have the following information:\n",
    "\n",
    "- a simple type (paragraph, list item, table)\n",
    "- its page number to have its approximate position in the document (beginning, middle, end, ...)\n",
    "- its context text, including :\n",
    "  - the description of the predicted section it belongs to\n",
    "  - the text rendering of the chunk content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from archaeo_super_prompt.types.pdfchunks import PDFChunkPerInterventionDataset\n",
    "\n",
    "SAMPLE_CHUNK_NUMBER = 4\n",
    "sample_chunks = chunks.sample(SAMPLE_CHUNK_NUMBER)\n",
    "\n",
    "Markdown(str(PDFChunkPerInterventionDataset(sample_chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Exploit the chunk information for the prompts\n",
    "\n",
    "The contextual text can be compared to the query with an embedding model.  \n",
    "The other information (type of content, position in the document, entity occurences) can also be used to select the best chunks for some extraction queries, according to the nature of the field to be extracted and the information we have about the excavation reports which compose the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry",
   "language": "python",
   "name": "poetry-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
