# -  1. If you use OPEN AI --

OPENAI_API_KEY=<your-openai-api-key>

# -- 2. If you use your own Ollama instance --

# additional environment variable for running ollama
# e.g., of the setting the usable gpus for a shared cluster,
# here, the nvidia gpus with id 0 et 1 could be used by ollama
OLLAMA_ENV_VARS="CUDA_VISIBLE_DEVICES=0,1"

REMOTE_SERVER_SSH_LOGIN=user@ollama-server-host
LOCAL_LLM_PORT=11434
REMOTE_OLLAMA_PORT=11434
OLLAMA_PATH_IN_REMOTE_SERVER="/path/to/your/ollama-server/bin/ollama"
